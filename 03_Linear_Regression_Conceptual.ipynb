{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.7 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conceptual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Describe the null hypothesis to which the p-values given in Table 3.4 (see  below) correspond. Explain what conclusions you can draw based on these p-values. Your explanation should be phrased in terms of _sales_, _TV_, _radio_, and _newspaper_, rathen than in terms of the coefficients of the linear model.\n",
    "    \n",
    "__Answers__\n",
    "\n",
    "1. Table 3.4\n",
    "\n",
    "|           | Coefficient | Std. error | t-statistic | p-value  |\n",
    "| --------- | ----------- | ---------- | ----------- | ---------|\n",
    "| Intercept | 2.939       | 0.3119     | 9.42        | < 0.0001 |\n",
    "| TV        | 0.046       | 0.0014     | 32.81       | < 0.0001 |\n",
    "| radio     | 0.189       | 0.0086     | 21.89       | < 0.0001 |\n",
    "| newspaper | -0.001      | 0.0059     | -0.18       | 0.8599   |\n",
    "\n",
    "According to the text:\n",
    "> \\[...\\] we interpret the p-value as follows: a small p-value indicates that it is unlikely to observe such a substantial association between the predictor and the response due to chance, \\[...\\] we can infer that there is an association between the predictor and the response. We reject the null hypothesis \\[...\\]\n",
    "\n",
    "The null hypothesis in this case is that there is no relationship between the response variable _sales_ and the predictors _TV_, _radio_, and _newspaper_. Based on the given p-values we can reject this hypothesis and conclude that there is, in fact, a relationship between _sales_ and the predictors _TV_ and _radio_. The p-value of _newspaper_ suggests that the relationship of _sales_ onto _newspaper_ is small. The reason given in the text is the correlation between _radio_ and _newspaper_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Carefully explain the differences between the KNN classifier and KNN regression methods.\n",
    "\n",
    "__Answers__\n",
    "1. The _KNN classifier_ is given by\n",
    " $$\n",
    " Pr(Y = j | X = x_0) = \\frac{1}{K}\\sum_{i\\in N_0}I(y_i=j)\n",
    " $$\n",
    " with $N_0$ being the set of the $K$ closest points to $x_0$ in the training data.\n",
    " \n",
    " On the other hand, the _KNN regression_ is given by\n",
    " $$\n",
    " \\hat f(x_0) = \\frac{1}{K}\\sum_{x_i\\in N_0}y_i\n",
    " $$\n",
    " with $N_0$ being the set of the $K$ closest points to $x_0$ in the training data. \n",
    " \n",
    " We see that the classifier returns a probability $Pr(Y = j | X = x_0)$ while the regression directly estimates the value of $f$ at $x_0$. To map the probablity onto a class the classifier uses the bayes rule and selects the class for which the probability is maximized. It follows that the classification can only return discrete values (the class identifiers) - the regression returns continuous values. Both methods depend on the neighbourhood of $x_0$ which leads to problems in higher dimensions (_curse of dimensionality_)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Suppose we have a data set with five predictors, $X_1 = $ GPA, $X_2 =$ IQ, $X_3 =$ Gender (1 for Female and 0 for Male), $X_4 = $ Interaction between GPA and IQ, and $X_5 = $ Interaction between GPA and Gender. The response is starting salary after graduation (in thousands of dollars). Suppose we use least squares to fit the model, and get $\\hat{\\beta}_0 = 50, \\hat{\\beta}_1 = 20, \\hat{\\beta}_2 = 0.07,\\hat{\\beta}_3 = 35,\\hat{\\beta}_4 = 0.01, \\hat{\\beta}_5 = -10$.\n",
    "\n",
    "    1. Which answer is correct and why?\n",
    "        1. For a fixed value of IQ and GPA, males earn more on average than females.\n",
    "        1. For a fixed value of IQ and GPA, females earn more on average than males.\n",
    "        1. For a fixed value of IQ and GPA, males earn more on average than females provided that the GPA is high enough.\n",
    "        1. For a fixed value of IQ and GPA, females earn more on average than males provided that the GPA is high enough.\n",
    "\n",
    "    1. Predict the salary of a female with IQ of 110 and a GPA of 4.0.\n",
    "    1. True or false: Since the coefficient for the GPA  / IQ interaction term is very small, there is very little evidence of an interaction effect. Justify your answer.\n",
    "    \n",
    "__Answers__\n",
    "\n",
    "1. We can write the model like this\n",
    "    $$\n",
    "    \\begin{align*}\n",
    "    Y &= \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_3 X_3 + \\beta_4 (X_1 X_2) + \\beta_5 (X_1 X_3) \\\\\n",
    "      &= \\beta_0 + (\\beta_1 + \\beta_4 X_2)X_1 + \\beta_2 X_2 + (\\beta_3 + \\beta_5 X_1)X_3 \\\\\n",
    "      &= \\beta_0 + (\\beta_1 + \\beta_4 X_2)X_1 + \\beta_2 X_2 + \\cases{\n",
    "          \\beta_3 + \\beta_5 X_1\\quad&\\text{if female} \\\\\n",
    "          0\\quad&\\text{if male}\n",
    "      } \\\\\n",
    "      &= 50 + (20 + 0.01 \\times IQ)\\times GPA + 0.07 \\times IQ + \\cases{\n",
    "          35 -10 \\times GPA\\quad&\\text{if female} \\\\\n",
    "          0\\quad&\\text{if male}\n",
    "      }\n",
    "    .\n",
    "    \\end{align*}\n",
    "    $$\n",
    "    \n",
    "    1. The model can be simplified further:\n",
    "      $$\n",
    "        \\begin{align*}\n",
    "        Y &= 50 + (20 + 0.01 \\times IQ)\\times GPA + 0.07 \\times IQ + \\cases{\n",
    "              35 -10 \\times GPA\\quad&\\text{if female} \\\\\n",
    "              0\\quad&\\text{if male}\n",
    "          }\\\\\n",
    "          &= \\cases{\n",
    "              50 + (20 + 0.01 \\times IQ)\\times GPA + 0.07 \\times IQ +35 -10 \\times GPA\\quad&\\text{if female} \\\\\n",
    "              50 + (20 + 0.01 \\times IQ)\\times GPA + 0.07 \\times IQ\\quad&\\text{if male}\n",
    "            }\\\\\n",
    "          &= \\cases{\n",
    "              85 + (10 + 0.01 \\times IQ)\\times GPA + 0.07 \\times IQ \\quad&\\text{if female} \\\\\n",
    "              50 + (20 + 0.01 \\times IQ)\\times GPA + 0.07 \\times IQ \\quad&\\text{if male}\n",
    "           }.\n",
    "        \\end{align*}\n",
    "        $$\n",
    "        We are interested in whether $85 + 10\\times GPA \\geq 50+20\\times GPA$. Assuming a GPA of $4.0$ gives $125 \\not\\geq 130$ which let's us conclude that answer number (c) is correct. Given a high enough GPA males earn more money on average.\n",
    "    \n",
    "    1. Plugging in the values gives\n",
    "     $$ \n",
    "     \\begin{align*}\n",
    "     salary &= 50 + 20 \\times GPA + 0.07\\times IQ + 35 \\times Gender + 0.01\\times  GPA \\times  IQ -10 \\times GPA \\times Gender \\\\\n",
    "            &= 50 + 20 \\times 4.0 + 0.07\\times 110 + 35 \\times 1 + 0.01\\times  4.0 \\times  110 -10 \\times 4.0 \\times 1 \\\\\n",
    "            &= 137.1.\n",
    "      \\end{align*}\n",
    "     $$\n",
    "    1. False: The value of the coefficient itself does not provide information about the importance of a term. Instead it is necessary to test the hypotheses $\\hat \\beta_4 = 0$ and to check the corresponding p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. I collect a set of data ($n = 100$ observations) containing a singe predictor and a quantitative response. I then fit a linear regression model to the data, as well as a separate cubic regression, i.e. $Y = \\beta_0 + \\beta_1X + \\beta_2X^2 + \\beta_3X^3 + \\epsilon$.\n",
    "\n",
    "    1. Suppose that the true relationship between X and Y is linear, i.e. $Y = \\beta_0 + \\beta_1X + \\epsilon$. Consider the training resudual sum of squares (RSS) for the linear regression. Would we expect one to be lower than the other, would we expect them to be the same, or is there not enough information to tell? Justify your answer.\n",
    "    1. Answer (a) using test rather than training RSS.\n",
    "    1. Suppose that the true relationship between X and Y is not linear, but we don't know how far it is from linear. Consider the training RSS for the linear regression, and also the training RSS for the cubic regression. Would we expect one to be lower than the other, would we expect them to be the same, or is there not enough information to tell? Justify your answer.\n",
    "    1. Answer (c) using test rather than training RSS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Consider the fitted values that result from performing linear regression without an intercept. In this setting, the $i$th fitted value takes the form\n",
    "\n",
    " $$\n",
    " \\hat{y}_i = x_i\\hat{\\beta},\n",
    " $$\n",
    " where\n",
    " $$\n",
    " \\hat{\\beta} = \\left(\\sum_{i=1}^nx_iy_i\\right) / \\left(\\sum_{i'=1}^nx_{i'}^2\\right).\n",
    " $$\n",
    " Show that we can write\n",
    " $$\n",
    " \\hat{y}_i = \\sum_{i'=1}^na_{i'}y_{i'}.\n",
    " $$\n",
    " What is $a_{i'}$?\n",
    " \n",
    " _Note: We interpret this result by saying that the fitted values from linear regression are_ linear combinations _of the response values._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using (3.4) (see below), argue that in the case of simple linear regression, the least squares line always passes through the point $(\\bar x, \\bar y)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. It is claimed in the text that in the case of simple linear regression of Y onto X, the R² statistic (3.17) (see below) is equal to the square of the correlation between X and Y (3.18) (see below). Prove that this is the case. For simplicity, you may assume that $\\bar x = \\bar y = 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
